{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be347187",
   "metadata": {},
   "source": [
    "# Ling 450/807 SFU - Assignment 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d845f6",
   "metadata": {},
   "source": [
    "## Approach 1: Using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ef8ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes extracted from C:\\Users\\User\\SDA250Mywork\\A1_data\\5c1452701e67d78e276ee126.txt:\n",
      "I was clear when I was mayor – I don’t support Uber at all,\n",
      "It was a twinkle in some engineer’s eye some years ago.\n",
      "Mayor McCallum’s statements vary greatly from truth,\n",
      "There’s a tried-and-true method in Canadian politics: after an election a new government takes office and says, ‘Oh my gosh, the cupboards are bare.’ Or, ‘We’re much deeper in debt than I thought we were, and now I’ve seen the real books.' So I think there’s an element of that kind of gamesmanship going on,\n",
      "Then there’s the fact that McCallum has been out of office for quite some time, thinking he knew the job, but some things have changed,\n",
      "If you take Fraser Highway SkyTrain and if we’re building that seven days a week around the clock, we probably can save, and this is TransLink’s figures, we can probably save $2-300 million,\n",
      "TransLink has not conducted any detailed study on potential construction methods for a SkyTrain route from Surrey to Langley. The most recent cost estimate (2017 Hatch report) did not consider construction schedules,\n",
      "We’ve also said in the past if we let large construction jobs build seven days a week, around the clock, we can reduce costs considerably,\n",
      "I’ve never said there’s a study.\n",
      "The Evergreen Line that was recently built, same distance, elevated all the way, actually goes through a tunnel, completed a year and a half ago, for only $1.4 billion,\n",
      "I care not about the technology. If Surrey wants to change to SkyTrain, that’s fine, but they’re going to get half as far as they would have with LRT,\n",
      "I think he’s trying to present the best possible case that he can fulfill his promises without too much financial pain, and to put it generously, he’s reading the spreadsheets optimistically,\n",
      "When the books were shown to me, I was deeply dismayed and shaken to the core to see how much debt the City of Surrey has been carrying,\n",
      "The fact that the debt load is at $514 million is simply untenable and frankly irresponsible.\n",
      "previously approved\n",
      "previously approved\n",
      "internal debt approved for the 2018-2022 General Capital Program.\n",
      "The city’s debt as far as the City of Surrey is $514 million, that’s in the financial statements, in the public documents that have gone out. I’ve never misstated that debt. So that’s there. We’ve passed a draft budget. It takes into consideration the very large debt that we need to bring down.\n",
      "We have one ice rink in South Surrey, we have one in Cloverdale, we have three in Fleetwood which is only 10 minutes from Cloverdale. We have one in Newton, and we have two in our city centre. We have three opening brand new in the middle of next year in Bridgeview, by the Patullo Bridge. We have the three new ones coming along with the current ones,\n",
      "We found that a little bit misleading, they were talking about all the new arenas, but in reality we won’t be gaining three. Two of the arenas will be taken away. You’re only getting one new rink,\n",
      "The land underneath is very unstable. Our engineering department says we would not be able to build this on unstable ground unless we used pile driving techniques to build it. Pile driving if anyone knows construction is very expensive construction. Originally it was planned to be $45 million, but that would increase considerably if we had to pile drive it.\n",
      "We have in the last eight to nine years had a declining use of ice for hockey. Each year it’s declining in participation and usage. We have a chart of that to show you,\n",
      "I know that our arenas are used more than what’s listed in that graph,\n",
      "That graph should go in the other direction.\n",
      "We could not supply one sheet of ice for them for any games all year,\n",
      "We’re turning away potential users because there’s nothing there.\n",
      "There are many possible reasons why the 2018 numbers appear low which may include waitlist accommodation, adding teaching stations, waitlist management. The numbers are being run from our stored data is not being modified.\n",
      "\n",
      "Quotes extracted from C:\\Users\\User\\SDA250Mywork\\A1_data\\5c146e42795bd2fcce2ea8e5.txt:\n",
      "playing games\n",
      "was clearly adopted to frustrate the applicants and not – as suggested – out of concern to maintain privacy.\n",
      "This has degenerated into an acrimonious fight,\n",
      "It needn’t be so adversarial.\n",
      "JAZZ.FM91 will respect the order of the Court.\n",
      "have a further statement next week. Stay tuned!\n",
      "very pleased with the decision. This really just levels the playing field and gives us an opportunity to talk to members about what our proposals are – and that’s all we ever wanted.\n",
      "The purpose of the meeting would be to vote out the incumbent board and then vote in a new board of directors proposed by Save JAZZ.FM91.\n",
      "tossing roadblocks in the way of democracy,\n",
      "it would be sending the wrong message\n",
      "because of the lack of good governance and transparency. I’m coming back because change is in sight, and if I can assist in bringing that positive change, I’m in with both feet.\n",
      "\n",
      "Quotes extracted from C:\\Users\\User\\SDA250Mywork\\A1_data\\5c149ffc1e67d78e276fbd44.txt:\n",
      "sextortion\n",
      "Cisco Talos discovered that this campaign is actually an evolution of sextortion and extortion attacks that we reported on in October. The claims in the emails we’ve seen from this actor are completely false, yet they have caused untold amounts of damage as organizations have evacuated buildings and called upon law enforcement to investigate,\n",
      "sextortion\n",
      "Multiple IPs involved in sending these bomb threats also sent various types of sextortion email that we saw in the previous campaign. In those cases, the attackers sent out emails claiming to have compromising videos of the victim and (threatened to) release them to the public unless the attacker (received) a bitcoin payment,\n",
      "We believe it’s the same group,\n",
      "We’re looking for similarities in the attack and when you see those similarities you pretty much know it’s the same group,\n",
      "innovation\n",
      "sextortion\n",
      "This game is all about getting a certain percentage of people to respond,\n",
      "The sextortion spam is not new. What’s new is they had a new twist that they thought could increase the amount of money they could make,\n",
      "While this caused chaos, it doesn’t look like it made them any money so they’ve moved on.\n",
      "What’s different here is that there is an easy way to exploit people, and that’s cryptocurrency. It’s fast, it’s virtual and it’s almost risk-free for the bad guys to do that,\n",
      "explode.\n",
      "They’re going to continue to throw things up against the wall and see what sticks until, eventually, when they hit at something that motivates people to actually pay that ransom, we’ll see that explode,\n",
      "We’ll see hundreds of thousands, millions of these emails. Everybody will start getting them in their mailbox.\n",
      "\n",
      "Quotes extracted from C:\\Users\\User\\SDA250Mywork\\A1_data\\5c15488f1e67d78e277161d7.txt:\n",
      "Justin Trudeau and the Liberals should pay attention to the riots happening in France. The people are revolting against carbon taxes, open immigration and the arrogance of the progressive socialist government,\n",
      "pay up and pollute all you want\n",
      "While Conservatives fiddle, the planet burns!\n",
      "goal post\n",
      "\n",
      "Quotes extracted from C:\\Users\\User\\SDA250Mywork\\A1_data\\5c1548a31e67d78e2771624f.txt:\n",
      "Some of those ‘soft’ skills are in short supply, but they’re what employers are looking for,\n",
      "There’s a societal cost to having someone remain unemployed,\n",
      "There are health-care costs. There are welfare costs. There can be criminal justice costs,\n",
      "road map\n",
      "should move to skills-based hiring,\n",
      "practices that prioritize … credentials and experience.\n",
      "These are things that are the least susceptible to technological disruption,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finding text within quotes\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Define function to extract text within quotes\n",
    "def get_quotes(text):\n",
    "    quotes = re.findall(r'“(.*?)”', text)\n",
    "    return quotes\n",
    "\n",
    "# Directory containing the text files\n",
    "directory = \"C:\\\\Users\\\\User\\\\SDA250Mywork\\\\A1_data\"\n",
    "\n",
    "# Process each text file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        print(f\"Quotes extracted from {file_path}:\")\n",
    "        quotes = get_quotes(text)\n",
    "\n",
    "        # Print the extracted quotes\n",
    "        for quote in quotes:\n",
    "            print(quote)\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929bfa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Approach 2: Using spaCy's Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28f3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b3b912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c1452701e67d78e276ee126.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca8af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c146e42795bd2fcce2ea8e5.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf5754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c149ffc1e67d78e276fbd44.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d9a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c15488f1e67d78e277161d7.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5577272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c1548a31e67d78e2771624f.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f352a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redo SpaCy Matcher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42998121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(16432004385153140588, 1625, 1629) “previously approved”\n",
      "(16432004385153140588, 1706, 1710) “previously approved”\n",
      "(16432004385153140588, 2727, 2738) “That graph should go in the other direction.”\n",
      "(16432004385153140588, 2769, 2787) “We could not supply one sheet of ice for them for any games all year,”\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c1452701e67d78e276ee126.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '“'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '”'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69921337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(16432004385153140588, 1625, 1629) “previously approved”\n",
      "(16432004385153140588, 1706, 1710) “previously approved”\n",
      "(16432004385153140588, 2727, 2738) “That graph should go in the other direction.”\n",
      "(16432004385153140588, 2769, 2787) “We could not supply one sheet of ice for them for any games all year,”\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c1452701e67d78e276ee126.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '“'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '”'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72d38c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(16432004385153140588, 24, 28) “playing games”\n",
      "(16432004385153140588, 215, 225) “This has degenerated into an acrimonious fight,”\n",
      "(16432004385153140588, 702, 712) “tossing roadblocks in the way of democracy,”\n",
      "(16432004385153140588, 713, 722) “it would be sending the wrong message”\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c146e42795bd2fcce2ea8e5.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '“'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '”'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6e7004b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(16432004385153140588, 19, 22) “sextortion”\n",
      "(16432004385153140588, 166, 169) “sextortion”\n",
      "(16432004385153140588, 471, 474) “innovation”\n",
      "(16432004385153140588, 477, 480) “sextortion”\n",
      "(16432004385153140588, 514, 530) “This game is all about getting a certain percentage of people to respond,”\n",
      "(16432004385153140588, 756, 760) “explode.”\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c149ffc1e67d78e276fbd44.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '“'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '”'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9f71cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(16432004385153140588, 128, 137) “pay up and pollute all you want”\n",
      "(16432004385153140588, 481, 485) “goal post”\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c15488f1e67d78e277161d7.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '“'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '”'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e0d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(16432004385153140588, 397, 401) “road map”\n",
      "(16432004385153140588, 628, 642) “These are things that are the least susceptible to technological disruption,”\n"
     ]
    }
   ],
   "source": [
    "with open (\"A1_data/5c1548a31e67d78e2771624f.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_q = [{'ORTH': '“'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '”'}]\n",
    "matcher.add(\"QUOTES\", [pattern_q], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
